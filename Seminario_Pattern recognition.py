# -*- coding: utf-8 -*-
"""Ejercicio_Haar Cascade.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19yA18BKnXR-nAADdKnUyBRO92qv3izZF

# Universidad Católica Luis Amigó
Seminario: Pattern recognition 2022-2
Docente: Juan Carlos Briñez de León
Estudiante: Mateo Tuberquia Gómez

# Ejercicio: Pattern recognition con clasificadores
"""

#1. Importando librerías.
import cv2 # OpenCV para computer vision
import numpy as np
import matplotlib.pyplot as plt #Para graficar

#Cargando datos
Ruta_dataset = '/content/drive/MyDrive/Material Luis Amigó/2022_2/Arquitectura de software/Taller reconocimiento facial/Ejercicio_2/Dataset'
Filas=560
Columnas=560

Target=7

Ruta=Ruta_dataset + '/' + str(Target+1) + '.jpg'
img=cv2.imread(Ruta)
I_gris=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
I_gris=cv2.resize(I_gris, (Filas,Columnas), interpolation = cv2.INTER_AREA)

plt.imshow(I_gris.astype('uint8'),cmap='gray',vmin=0, vmax=255)
plt.show

#Detectando rostro
Detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
Cara = Detector.detectMultiScale(I_gris, scaleFactor=1.1, minNeighbors=5, minSize=(20,20), maxSize=(300,300))
for (x,y,w,h) in Cara:
    Recorte=I_gris[y:y+h,x:x+w]
    plt.imshow(Recorte.astype('uint8'),cmap='gray',vmin=0, vmax=255)
    plt.show

del Cara

# Corriendo todo el proceso de extracción del dataset
Filas2=100
Columnas2=100
Dataset=np.zeros((35,Filas2*Columnas2+1))

for i in range(1,36,1):
  Ruta=Ruta_dataset + '/' + str(i) + '.jpg'
  img=cv2.imread(Ruta)
  I_gris=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  I_gris=cv2.resize(I_gris, (Filas,Columnas), interpolation = cv2.INTER_AREA)

  Cara = Detector.detectMultiScale(I_gris, scaleFactor=1.1, minNeighbors=10, minSize=(20,20), maxSize=(300,300))

  for (x,y,w,h) in Cara:
    Recorte=I_gris[y:y+h,x:x+w]
    
  
  del Cara
  Recorte=cv2.resize(Recorte, (Filas2,Columnas2))
  Dataset[i-1,0:Filas2*Columnas2]=Recorte.reshape((1,Filas2*Columnas2))
  if i>=1 and i<=5:
    Dataset[i-1,Filas2*Columnas2]=1
  else:
    if i>=6 and i<=10:
      Dataset[i-1,Filas2*Columnas2]=2
    else:
      if i>=11 and i<=15:
        Dataset[i-1,Filas2*Columnas2]=3
      else:
        if i>=16 and i<=20:
          Dataset[i-1,Filas2*Columnas2]=4
        else:
          if i>=21 and i<=25:
            Dataset[i-1,Filas2*Columnas2]=5
          else:
            if i>=26 and i<=30:
              Dataset[i-1,Filas2*Columnas2]=6
            else:
                Dataset[i-1,Filas2*Columnas2]=7

print(Dataset.shape)

#2. Dividing dataset into input (X) and output (Y) variables
X = Dataset[:,0:Filas2*Columnas2]
Y = Dataset[:,Filas2*Columnas2]
print(X.shape)
print(Y.shape)
print(Y)

#Dividiendo el conjunto de imágenes
import sklearn
from sklearn.model_selection import train_test_split
X_train, X_test,Y_train, Y_test= train_test_split(X,Y,test_size=0.2,random_state=14541)
print(X_train.shape)
print(Y_train.shape)
print(X_test.shape)
print(Y_test.shape)

# Recuperando y mostrando imágenes del dataset
Target=25
Imagen=X_train[Target,:]
Imagen=Imagen.reshape((Filas2,Columnas2))
plt.imshow(Imagen.astype('uint8'),cmap='gray',vmin=0, vmax=255)
print('Este es el sugeto número: ',Y_train[Target])

# Data normalization
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""==================================================================="""

#5. Evaluando casos mediante todos los clasificadores
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score,precision_score

Modelo_0 = KNeighborsClassifier(3)
Modelo_0.fit(X_train, Y_train)
Y_pred_0 =Modelo_0.predict (X_test)
print("Accuracy KNN",accuracy_score(Y_test, Y_pred_0))

Modelo_1 = GaussianNB()
Modelo_1.fit(X_train, Y_train)
Y_pred =Modelo_1.predict (X_test)
print("Accuracy Bayes",accuracy_score(Y_test, Y_pred))

Modelo_2 = LinearDiscriminantAnalysis()
Modelo_2.fit(X_train, Y_train)
Y_pred_2 =Modelo_2.predict (X_test)
print("Accuracy LDA",accuracy_score(Y_test, Y_pred_2))

Modelo_3 = QuadraticDiscriminantAnalysis()
Modelo_3.fit(X_train, Y_train)
Y_pred_3 =Modelo_3.predict (X_test)
print("Accuracy QDA",accuracy_score(Y_test, Y_pred_3))

Modelo_4 = DecisionTreeClassifier()
Modelo_4.fit(X_train, Y_train)
Y_pred_4 =Modelo_4.predict (X_test)
print("Accuracy Tree",accuracy_score(Y_test, Y_pred_4))

Modelo_5 = SVC()
Modelo_5.fit(X_train, Y_train)
Y_pred_5 =Modelo_5.predict (X_test)
print("Accuracy SVM",accuracy_score(Y_test, Y_pred_5))

#Reviewing an specific dataset target
Test=3
Target=np.zeros((1,Filas2*Columnas2))
Target[0,:]=X_test[Test,:]
Target_im=Target[0,:].reshape((Filas2,Columnas2))*255

Prediction_0 =Modelo_0.predict (Target)
Prediction_1 =Modelo_1.predict (Target)
Prediction_2 =Modelo_2.predict (Target)
Prediction_3 =Modelo_3.predict (Target)
Prediction_4 =Modelo_4.predict (Target)
Prediction_5 =Modelo_5.predict (Target)
print("La predicción de KNN es:",Prediction_0,', y debería ser: ',Y_test[Test])
print("La predicción de Bayes es:",Prediction_1,', y debería ser: ',Y_test[Test])
print("La predicción de LDA es:",Prediction_2,', y debería ser: ',Y_test[Test])
print("La predicción de QDA es:",Prediction_3,', y debería ser: ',Y_test[Test])
print("La predicción de Tree es:",Prediction_4,', y debería ser: ',Y_test[Test])
print("La predicción de SVM es:",Prediction_5,', y debería ser: ',Y_test[Test])

"""#Mejorando resultados con descriptores

Validando resultados
"""

#Cargando datos rostros Pascual
Ruta_dataset = '/content/drive/MyDrive/Material Luis Amigó/2022_2/Arquitectura de software/Taller reconocimiento facial/Ejercicio_2/Dataset_Val'
Test=11
Ruta=Ruta_dataset + '/' + str(Test) + '.jpg'
img=cv2.imread(Ruta)
plt.imshow(img[:,:,[2,1,0]].astype('uint8'),cmap='gray',vmin=0, vmax=255)
Filas=128
Columnas=128
Target=np.zeros((1,Filas*Columnas))
I_gris=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
I_gris=cv2.resize(I_gris, (Filas,Columnas), interpolation = cv2.INTER_AREA)
Target[0,0:Filas*Columnas]=I_gris.reshape((1,Filas*Columnas))
Target = scaler.transform(Target)
Prediction_0 =Modelo_0.predict (Target)
if Prediction_0==1:
   print("La predicción de KNN es: Anderson Correa")
else:
  if Prediction_0==2:
   print("La predicción de KNN es: Andrés Romero")
  else:
    if Prediction_0==3:
      print("La predicción de KNN es: Carlos valencia")
    else:
      if Prediction_0==4:
        print("La predicción de KNN es: Carlos Bonilla")
      else:
        if Prediction_0==5:
          print("La predicción de KNN es: Crístian Ramos")
        else:
          if Prediction_0==6:
            print("La predicción de KNN es: Gabriel Vélez")
          else:
            print("La predicción de KNN es: Jeferson Hurtado")

"""https://www.enmilocalfunciona.io/tratamiento-de-imagenes-usando-imagedatagenerator-en-keras/

https://whythinkaloud.com/2020/03/15/imagedatagenerator-is-one-of-the-coolest-things-in-keras/
"""